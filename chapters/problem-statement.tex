\chapter{Problem Statement}\label{chapter:problem-statment}


Integration of a system of ODEs by means of W-methods can be considered as a solution of a sequence of linear systems from another point of view. Equations \ref{eq:athlet-9} can be rewritten in a form \ref{eq:athlet-10}, after grouping both the right- and left-hand sides in a single matrix and vector, respectively.\\


\begin{equation} \label{eq:athlet-10}
	A_{i} \Delta z^{l}_{i} =  b^{l}_{i} 
\end{equation}

where $A = ((h \gamma)^{-1}I - J)$ is a $\mathbb{R}^{N} \times \mathbb{R}^{N}$ non-singular sparse matrix, $\Delta z^{l}_{i}$  and $b^{l}_{i}$ are $\mathbb{R}^{N}$ vectors.\\


According to the integration scheme, figure \ref{fig:introduction-w-method-scheme}, and definition of the method, each step of numerical integration requires to solve 6 linear systems with 3 distinct matrices, resulting from the Jacobian matrix by the corresponding shifts of the main diagonal. Therefore, the computational burden of the W-method mainly lies in solving of sparse linear systems.\\


There exist two families of linear sparse solvers, namely: iterative and direct sparse methods. In the general case, execution time of any algorithm, regardless of the solver family, is bounded by $O(N^2)$ complexity due to matrix sparsity, where $N$ is number of equations in the system. However, the constant in front of the factor $N^2$ can vary significantly across the methods which explains the differences in execution time. Additionally, it is important to mention the families use absolutely different approaches for solution of sparse linear systems and thus posses different numerical properties. Among all the properties, there are some which are particularly important for efficient execution of W-methods, namely: \\


\begin{itemize}
	\item robustness (or numerical stability) with respect to ill-conditioner problems
	\item numerical accuracy
	\item parallel efficiency, with emphasis on strong scaling 
\end{itemize}


These above mentioned properties can be treated as non-functional requirements for a sparse linear solver for efficient numerical time integration.\\

 
Finding solutions of sparse linear systems is a well-known and commonly occurring problem in the field of scientific computing and, therefore, numerous implementations of different kind of linear solvers exist. However, the NuT project imposes some extra constrains due to the design philosophy adopted by GRS: \\


\begin{itemize}
	\item open-source license
	\item direct interface to PETSc
\end{itemize}

%In particular, it requires a particular solver implementation to have its \textbf{open-source license} and to have its direct \textbf{interface to PETSc} library.\\


In this study, we are primarily concerned with selection and configuration of a linear sparse solver that can cover all requirements listed above.\\


This report is organized as follows. Chapter \ref{subseq:matrix-sets-and-hardware} provides full information about the experimental setup and matrix sets used in the study. Chapters BRA and BRA explain theory and some parallelization aspects of iterative and sparse direct methods, respectively, using a  well-known representative-algorithm of each type as an example. In chapter BRA, we give a short summary and conclude which type of sparse linear solvers is the best suited for time integration governed by the W-method. In chapter BRA, we represent a list of solvers, according to the chosen type, available at the time of writing, and perform initial tests with the aim of finding the fastest solver of the corresponding type. From chapter BRA onwards, we focus on configuration of a specific solver to reduce its execution time. Chapter BRA sums up overall results of the performed configuration and, in chapter BRA, we give some recommendations to the ATHLET users about which solver parameters are better to use for a specific matrix size: small, medium, large.\\


An additional topic, considered in this study, is improvement of ATHLET-NuT communication during Jacobian matrix transfer. As it was described in section \ref{sec:athlet-nut-coupling}, ATHLET, the client, transfers Jacobian matrix in a column-wise fashion. NuT, the server, treats each column transfer as a service and, therefore, each transfer passes through a 3-way handshake. Moreover, it is important to mention one more time,   due to the current implementation of ATHLET-NuT coupling, the client-server communication is blocking. In other words, ATHLET gets blocked till completion of a column transfer. \\


The main goal of Jacobian matrix compression, described in section \ref{sec:jacobian-matrix-compression}, is to minimize the number of perturbations of non-linear function $f(y)$, equation \ref{eq:athlet-8}, derived from finite differences. Additionally it allows to reduce the amount of column transfers as well. Therefore, it improves overall application performance from both computational and communication point of view. However, there are still some aspects to be considered.\\


Due to specifics of matrix compression algorithm, described in section \ref{sec:athlet-nut-coupling}, column length is decreasing between the first and last columns of compressed Jacobian matrix form which, as a result, leads to unequal MPI message sizes.\\


In this part of the study, we introduce a concept called \textit{accumulator} which allows to transfer a compressed Jacobian matrix in equal chunks. This approach potentially solves three important problems at once. First of all, \textit{accumulator} can help to get rid of small MPI messages and thus improves network bandwidth utilization. Secondly, it helps to reduce the amount of synchronizations between the client and server and, therefore, improves operation of NuT as the server. Lastly, it allows to apply non-blocking MPI communication on the client side and thus overlap Jacobian matrix transfer with its computations.\\


In section \ref{sec:jacobian-matrix-compression}, we briefly describe the Jacobian matrix compression algorithm and the resulting ATHLET-NuT communication problem. In section \ref{sec:accumulator-approach}, we present and describe the algorithm which is supposed to resolve the problem. Section \ref{sec:benchmark-and-test-data} provides a description of developed benchmarks and test data. Then, we focus and explain obtained results in section \ref{sec:accumulator-results}. Finally, in section \ref{sec:accumulator-conclusions}, we provide a general conclusion of the performed study and summarize the results one more time.\\
